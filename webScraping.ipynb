{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleta de dados: Web Scraping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minha identificação ao usar o navegador para acessar sites com o Google Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificação do \"Usuário agente\"\n",
    "agente = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "# Criando chave de identificação\n",
    "headers = { 'User-Agente': agente }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processo de scraping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Coletando HTML de site**\n",
    "<font size = '3'>\n",
    "Essa atividade será executada pela função 'htmlSite', que fará a requisição do código HTML do site e ajustá-lo.<br>\n",
    "\n",
    "Obs:<br>\n",
    "\n",
    "Para que a função funcione, é necessário o Usuário agente (headers) do seu navegador (Chrome), para que <br>\n",
    "possa ser requerido o conteúdo do site, que virá em formato de byte. A partir disso transformamos o <br>\n",
    "formato byte usando a codificação correta, tornando-o texto e, em seguida, estruturando-o como objeto <br>\n",
    "BeautifulSoup, para futuras consultas de tags.    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para extrair o código HTML do site de interesse\n",
    "def htmlSite( url: str ) -> str:\n",
    "\n",
    "    try:\n",
    "        # Fazendo requisição de acesso ao html do link\n",
    "        requisicao = requests.get( url, headers = headers, timeout = 4 )\n",
    "\n",
    "        # Conteúdo do site ilegível e em formato byte\n",
    "        resposta_bytes = requisicao.content\n",
    "\n",
    "        # Conteúdo do site em formato de texto, ainda ilegível\n",
    "        html_pagina = resposta_bytes.decode( 'latin1' )\n",
    "\n",
    "        # Texto html corrido, separado por tags, perfeitamente legível\n",
    "        return bs4.BeautifulSoup( html_pagina, 'html.parser' )\n",
    "\n",
    "    # Caso falhe, apenas passe, não trave a execução do scrip geral\n",
    "    except: pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extração de dados do HTML**\n",
    "<font size = '3'>\n",
    "Essa atividade será executada pela função 'dadosProposicao', que extrairá dados de tags de <br>\n",
    "interesse e armazenará em um DataFrame pandas.<br>\n",
    "\n",
    "A url das proposições segue um padrão, onde 1º temos o tipo de proposição, logo após o número dela e, por fim, <br>\n",
    "o ano em que a respectiva foi realizada; dessa forma, com o uso de iterações podemos fazer requisições em larga <br>\n",
    "escala e extrair os dados. <br>\n",
    "\n",
    "Um ponto de obervação que devemos ter é a possibilidade de a página requisitada não retornar dados, por exemplo: <br>\n",
    "no ano de 20xx tiveram 1.000 proposições, e na nossa requisição procuramos pela número 1.001... ela irá falhar. <br>\n",
    "Dessa forma, identifiquei dois padrões: quando a proposição requisitada não existe ou não está disponível e armazenei <br>\n",
    "na variável 'condicoes'. Após isso, com auxílio de um if, construí um bloco de verificação.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para, a partir do HTML do site da prefeitura, coletar dados das tags de interesse e armazenar em um DataFrame\n",
    "def dadosProposicao( ano: int, num_proposicao: int, tipo_proposicao: int ) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "        ano               (int): ano em que as proposições foram realizadas;\n",
    "        num_proposicao    (int): Define a partir de qual proposição iniciará a extração;\n",
    "        tipo_proposicao   (int): definir se a proposição é uma indicação (1), requerimento (2) ou moção (3).\n",
    "    \"\"\"\n",
    "\n",
    "    # Url do site, para encontrar a preposição\n",
    "    site = f'https://www.legislador.com.br//LegisladorWEB.ASP?WCI=ProposicaoTexto&ID=3&TPProposicao={ tipo_proposicao }&nrProposicao={ num_proposicao }&aaProposicao={ ano }'\n",
    "\n",
    "    # HTML do site\n",
    "    html = htmlSite( site )\n",
    "\n",
    "    # VERIFICAÇÃO DE PROPOSIÇÃO INEXISTENTE ----------------------------------------------\n",
    "\n",
    "    condicoes = ( ( html.find_all( 'dt' ) == []               ) or # Verifica se as tags onde guardam os nomes das colunas existem\n",
    "                  ( 'Proposição não existente' in str( html ) ) )  # Verifica se a substring está contida no HTML\n",
    "\n",
    "    # COLETANDO DADOS DO SITE ------------------------------------------------------------\n",
    "\n",
    "    # Se a proposição não existir, retorne um erro no output; se existir, colete os dados\n",
    "    if  condicoes: raise ValueError()\n",
    "\n",
    "    else:\n",
    "        # Criando estrutura do DataFrame esperado\n",
    "        dfEstrutural = pd.DataFrame( columns = ['Reunião', 'Deliberação', 'Situação', 'Assunto', 'Autor', 'Proposição', 'Ano', 'Texto'] )\n",
    "\n",
    "        # Coletando apenas tags de interesse\n",
    "        html_colunas = html.find_all( 'dt' ) # No HTML do site, 'dt' é a tag com o nome das colunas \n",
    "        html_linha   = html.find_all( 'dd' ) # No HTML do site, 'dd' é a tag em que o conteúdo da linha está contido\n",
    "\n",
    "        # Gerando DataFrame com todos os textos contidos nas tags de interesse\n",
    "        dados = pd.DataFrame( columns = [   i.get_text() for i in html_colunas  ],\n",
    "                              data    = [ [ i.get_text() for i in html_linha  ] ] ) # É necessário envolver em lista dupla\n",
    "\n",
    "        # Registrando informações que não estão nas tags consultadas\n",
    "        dados['Proposição'] = num_proposicao\n",
    "        dados['Ano'       ] = ano\n",
    "        dados['Texto'     ] = html.p.get_text()\n",
    "\n",
    "        # Concantenando para, caso a proposição não tiver dados de uma coluna, a estrutura da tabela não se alterar\n",
    "        df = pd.concat( [ dfEstrutural, dados ] )\n",
    "\n",
    "    return df.rename( columns = { 'Reunião'    : 'dt_reuniao',\n",
    "                                  'Deliberação': 'dt_deliberacao',\n",
    "                                  'Situação'   : 'situacao',\n",
    "                                  'Assunto'    : 'assunto',\n",
    "                                  'Autor'      : 'autor',\n",
    "                                  'Proposição' : 'proposicao',\n",
    "                                  'Ano'        : 'ano',\n",
    "                                  'Texto'      : 'texto' } )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteração: extração de dados em larga escala**\n",
    "<font size = '3'>\n",
    "Tendo acesso ao HTML e construído o código de extração de seus dados, o foco agora é direcionado <br>\n",
    "para coleta em larga escala, tarefa que será executada pela função 'tabelaResultado'.<br>\n",
    "\n",
    "Para isso, alguns pontos nortearam a construção do código construído:<br>\n",
    "1. a mecânica de loop escolhida, no caso, a while será utilizada nesse projeto;<br>\n",
    "2. a quantidade de vezes seguidas em que houver erro na requisição de proposições, para parar a execução e;<br>\n",
    "3. a quantidade de tempo entre uma extração e outra, para não sobrecarregar o site. <br>\n",
    "\n",
    "O resultado será um pd.DataFrame com os dados coletados.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função com loop para realizar consultas às páginas no site e gerar uma tabela com o resultado\n",
    "def tabelaResultado( ano: int, tipo_proposicao: int, inicia_em: int, qtd_requisicoes: int, erros_admissiveis: int, seg_espera: float ):\n",
    "\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "        ano                 (int): ano em que as proposições foram realizadas;\n",
    "        tipo_proposicao     (int): definir se a proposição é uma indicação (1), requerimento (2) ou moção (3).\n",
    "        inicia_em           (int): Define a partir de qual proposição iniciará a extração;\n",
    "        qtd_requisicoes     (int): Define quantas requisições serão realizadas a partir da 'inicia_em';\n",
    "        erros_admissiveis   (int): quantas vezes a requisição pode falhar até entender que não há mais dados.\n",
    "        seg_espera        (float): quantidade de tempo de espera até realizar próxima execução.\n",
    "    \"\"\"\n",
    "\n",
    "    # Variáveis do loop\n",
    "    ult_consulta     = inicia_em + qtd_requisicoes - 1 # O número da última proposição a ser consultada\n",
    "    erros_ocorridos  = 0\n",
    "    lista_dataFrames = []\n",
    "    qtd_consultas    = 1 # Quantidade de consultas realizadas\n",
    "\n",
    "    # Iteração\n",
    "    while inicia_em <= ult_consulta and erros_ocorridos < erros_admissiveis:\n",
    "\n",
    "        try:\n",
    "            # Se não falhar, retornará dicionário com dados da proposição\n",
    "            dados = dadosProposicao(  ano, inicia_em, tipo_proposicao )\n",
    "\n",
    "            # Adicionando dicionário na lista criada\n",
    "            lista_dataFrames.append( dados )\n",
    "\n",
    "        # Caso a função falhe, registrará o erro\n",
    "        except: erros_ocorridos += 1\n",
    "        pass\n",
    "\n",
    "        # Registrando em tela a quantidade de consultas realizadas\n",
    "        print( f'{ qtd_consultas } Consulta(s) efetuada(s). { seg_espera } segundos para próxima execução.' )\n",
    "\n",
    "        # Variáveis incrementais: adicionando 1 a cada nova consulta\n",
    "        inicia_em     += 1\n",
    "        qtd_consultas += 1\n",
    "\n",
    "        # Aguardar a quantidade de tempo definida para continuar o loop\n",
    "        time.sleep( seg_espera )\n",
    "\n",
    "    return pd.concat( lista_dataFrames )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
